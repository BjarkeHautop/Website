[
  {
    "objectID": "projects/pkg_2/index.html",
    "href": "projects/pkg_2/index.html",
    "title": "pkg_2",
    "section": "",
    "text": "This package does this."
  },
  {
    "objectID": "projects/notes_rms/notes_rms.html",
    "href": "projects/notes_rms/notes_rms.html",
    "title": "Notes to Regression Modelling Strategies by Frank Harrell",
    "section": "",
    "text": "These are my notes to the book “Regression Modelling Strategies” by Frank Harrell. The notes are based on things I found interesting and learned. R code and figures are included when relevant."
  },
  {
    "objectID": "projects/notes_rms/notes_rms.html#sections",
    "href": "projects/notes_rms/notes_rms.html#sections",
    "title": "Notes to Regression Modelling Strategies by Frank Harrell",
    "section": "Sections",
    "text": "Sections\nMy notes have the following sections\n\nIssues with step-wise variable selection\nShould one assume a linear relationship?\nPrediction\nValidation\nNomograms\n\nClick here to download my notes"
  },
  {
    "objectID": "projects/cox_model/cox.html",
    "href": "projects/cox_model/cox.html",
    "title": "Cox model case study",
    "section": "",
    "text": "Analyzing prostate cancer dataset using a Cox model. The primary goal is to discover patterns in survival, and to do an analysis of covariance to assess the effect of treatment while adjusting for patient heterogeneity. Prediction is a secondary goal."
  },
  {
    "objectID": "projects/cox_model/cox.html#loading-data",
    "href": "projects/cox_model/cox.html#loading-data",
    "title": "Cox model case study",
    "section": "Loading data",
    "text": "Loading data\n\nlibrary(Hmisc)\nlibrary(survival)\nlibrary(rms)\nlibrary(scales)\nlibrary(ggplot2)\nlibrary(latex2exp)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(modelsummary)\ngetHdata(prostate)\n\nWe start by showing summary of all the variables in the dataset\n\n\nClick here to see output\n\nPreprocess data for function datasummary_skim.\n\nprostate_summary &lt;- prostate\n\n# Convert 'labelled' columns to numeric\nprostate_summary[] &lt;- lapply(prostate_summary, function(x) {\n  if (inherits(x, \"labelled\")) {\n    as.numeric(x)\n  } else {\n    x\n  }\n})\n\nprostate_summary$bm &lt;- as.factor(prostate$bm)\nprostate_summary$stage &lt;- as.factor(prostate$stage)\nprostate_summary$hx &lt;- as.factor(prostate$hx)\n\nprostate_summary &lt;- prostate_summary[, !names(prostate) %in% c(\"patno\", \"sdate\")]\n\nfactors &lt;- sapply(prostate_summary, is.factor)\n\nSummary of factor variables in data\n\ndatasummary_skim(prostate_summary[factors])\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                \n                \n                N\n                %\n              \n        \n        \n        \n                \n                  stage\n                  3\n                  289\n                  57.6\n                \n                \n                  \n                  4\n                  213\n                  42.4\n                \n                \n                  rx\n                  placebo\n                  127\n                  25.3\n                \n                \n                  \n                  0.2 mg estrogen\n                  124\n                  24.7\n                \n                \n                  \n                  1.0 mg estrogen\n                  126\n                  25.1\n                \n                \n                  \n                  5.0 mg estrogen\n                  125\n                  24.9\n                \n                \n                  status\n                  alive\n                  148\n                  29.5\n                \n                \n                  \n                  dead - prostatic ca\n                  130\n                  25.9\n                \n                \n                  \n                  dead - heart or vascular\n                  96\n                  19.1\n                \n                \n                  \n                  dead - cerebrovascular\n                  31\n                  6.2\n                \n                \n                  \n                  dead - pulmonary embolus\n                  14\n                  2.8\n                \n                \n                  \n                  dead - other ca\n                  25\n                  5.0\n                \n                \n                  \n                  dead - respiratory disease\n                  16\n                  3.2\n                \n                \n                  \n                  dead - other specific non-ca\n                  28\n                  5.6\n                \n                \n                  \n                  dead - unspecified non-ca\n                  7\n                  1.4\n                \n                \n                  \n                  dead - unknown cause\n                  7\n                  1.4\n                \n                \n                  pf\n                  normal activity\n                  450\n                  89.6\n                \n                \n                  \n                  in bed &lt; 50% daytime\n                  37\n                  7.4\n                \n                \n                  \n                  in bed &gt; 50% daytime\n                  13\n                  2.6\n                \n                \n                  \n                  confined to bed\n                  2\n                  0.4\n                \n                \n                  hx\n                  0\n                  289\n                  57.6\n                \n                \n                  \n                  1\n                  213\n                  42.4\n                \n                \n                  ekg\n                  normal\n                  168\n                  33.5\n                \n                \n                  \n                  benign\n                  23\n                  4.6\n                \n                \n                  \n                  rhythmic disturb & electrolyte ch\n                  51\n                  10.2\n                \n                \n                  \n                  heart block or conduction def\n                  26\n                  5.2\n                \n                \n                  \n                  heart strain\n                  150\n                  29.9\n                \n                \n                  \n                  old MI\n                  75\n                  14.9\n                \n                \n                  \n                  recent MI\n                  1\n                  0.2\n                \n                \n                  bm\n                  0\n                  420\n                  83.7\n                \n                \n                  \n                  1\n                  82\n                  16.3\n                \n        \n      \n    \n\n\n\nSummary of continuous variables in data\n\ndatasummary_skim(prostate_summary[!factors])\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                \n                Unique\n                Missing Pct.\n                Mean\n                SD\n                Min\n                Median\n                Max\n                Histogram\n              \n        \n        \n        \n                \n                  dtime\n                  76\n                  0\n                  36.1\n                  23.3\n                  0.0\n                  34.0\n                  76.0\n                  \n                \n                \n                  age\n                  42\n                  0\n                  71.5\n                  7.1\n                  48.0\n                  73.0\n                  89.0\n                  \n                \n                \n                  wt\n                  68\n                  0\n                  99.0\n                  13.4\n                  69.0\n                  98.0\n                  152.0\n                  \n                \n                \n                  sbp\n                  18\n                  0\n                  14.4\n                  2.4\n                  8.0\n                  14.0\n                  30.0\n                  \n                \n                \n                  dbp\n                  12\n                  0\n                  8.1\n                  1.5\n                  4.0\n                  8.0\n                  18.0\n                  \n                \n                \n                  hg\n                  91\n                  0\n                  13.4\n                  2.0\n                  5.9\n                  13.7\n                  21.2\n                  \n                \n                \n                  sz\n                  56\n                  1\n                  14.6\n                  12.3\n                  0.0\n                  11.0\n                  69.0\n                  \n                \n                \n                  sg\n                  12\n                  2\n                  10.3\n                  2.0\n                  5.0\n                  10.0\n                  15.0\n                  \n                \n                \n                  ap\n                  128\n                  0\n                  12.2\n                  62.2\n                  0.1\n                  0.7\n                  999.9\n                  \n                \n        \n      \n    \n\n\n\n\nWe see that the variable ekg only has one observation in the last category and pf has two. So, we combine recent MI with old MI and call it MI, and we combine confined to bed with \\(&gt;50\\%\\) daytime.\n\nlevels(prostate$ekg)[levels(prostate$ekg) %in%\n  c(\"old MI\", \"recent MI\")] &lt;- \"MI\"\n\nlevels(prostate$pf) &lt;- c(\n  levels(prostate$pf)[1:3],\n  levels(prostate$pf)[3]\n)"
  },
  {
    "objectID": "projects/cox_model/cox.html#imputing-missing-values",
    "href": "projects/cox_model/cox.html#imputing-missing-values",
    "title": "Cox model case study",
    "section": "Imputing missing values",
    "text": "Imputing missing values\nWe have 27 patients with missing values as seen below, so we do imputation on these.\nThe proportion of missing values is \\(0.05\\), so we just do single imputation, since simpler to make plots and validation. However if the proportion were higher one should do multiple imputation.\n\nsum(is.na(prostate))\n\n[1] 27\n\ncolSums(is.na(prostate))\n\n patno  stage     rx  dtime status    age     wt     pf     hx    sbp    dbp \n     0      0      0      0      0      1      2      0      0      0      0 \n   ekg     hg     sz     sg     ap     bm  sdate \n     8      0      5     11      0      0      0 \n\nw &lt;- transcan(\n  ~ sz + sg + ap + sbp + dbp + age +\n    wt + hg + ekg + pf + bm + hx,\n  imputed = TRUE,\n  data = prostate, pl = FALSE, pr = FALSE\n)\n\nattach(prostate)\nsz &lt;- impute(w, sz, data = prostate)\nsg &lt;- impute(w, sg, data = prostate)\nage &lt;- impute(w, age, data = prostate)\nwt &lt;- impute(w, wt, data = prostate)\nkg &lt;- impute(w, ekg, data = prostate)"
  },
  {
    "objectID": "projects/cox_model/cox.html#data-reduction-using-domain-knowledge",
    "href": "projects/cox_model/cox.html#data-reduction-using-domain-knowledge",
    "title": "Cox model case study",
    "section": "Data reduction using domain knowledge",
    "text": "Data reduction using domain knowledge\nWe do the following changes\n\nCombine systolic blood pressure (sbp) and diastolic blood pressure (dbp) into Mean Arterial Pressure.\nCombine history of cardiovascular disease (hx) and electrocardiogram code ekg and assume linear. We code it as 2 if ekg are not normal or benign and hx, 1 if either, and 0 if none.\nWeight index not that important, so only use 3 knots.\nTake log of Serum prostatic acid phosphatase (ap) for numeric stability (heavy right-tail) and allow 1 more knot for compensation\nThe tumor variables tumor size (sz) and stage/histologic grade combination (sg) should be important variables, but since we have both we keep them but give them only 3 knots each.\nAssume performance rating (pf) is linear.\n\n\nmap &lt;- (2 * dbp + sbp) / 3\nlabel(map) &lt;- \"Mean Arterial Pressure/10\"\n\nheart_d &lt;- hx + ekg %nin% c(\"normal\", \"benign\")\nlabel(heart_d) &lt;- \"Heart Disease Code\"\n\npf_linear &lt;- as.numeric(pf)\n\nSo all in all we save 3 degrees of freedom from defining map, 5 for defining Heart Disease Code, and 3 for dropping knots, 1 for assuming performance rating is linear and gain 1 from ap. For a total reduction of 11 degrees of freedom.\n\ndd &lt;- datadist(dd, heart_d, map, pf_linear)\n\nf &lt;- cph(\n  S ~ rx + rcs(age, 4) + rcs(wt, 3) + pf_linear + heart_d + rcs(map, 3)\n    + rcs(hg, 4) + rcs(sg, 3) + rcs(sz, 3) + rcs(log(ap), 5) + bm,\n  x = TRUE, y = TRUE, surv = TRUE, time.inc = 5 * 12\n)\n\nprint(f, html = TRUE, coefs = 3)\n\nCox Proportional Hazards Model\n\ncph(formula = S ~ rx + rcs(age, 4) + rcs(wt, 3) + pf_linear + \n    heart_d + rcs(map, 3) + rcs(hg, 4) + rcs(sg, 3) + rcs(sz, \n    3) + rcs(log(ap), 5) + bm, x = TRUE, y = TRUE, surv = TRUE, \n    time.inc = 5 * 12)\n\n                        Model Tests     Discrimination    \n                                               Indexes    \nObs        502    LR chi2    119.86     R2       0.212    \nEvents     354    d.f.           24    R2(24,502)0.174    \nCenter -2.3792    Pr(&gt; chi2) 0.0000    R2(24,354)0.237    \n                  Score chi2 126.89     Dxy     -0.323    \n                  Pr(&gt; chi2) 0.0000                       \n\n                   Coef     S.E.    Wald Z Pr(&gt;|Z|)\nrx=0.2 mg estrogen   0.0005  0.1492  0.00  0.9975  \nrx=1.0 mg estrogen  -0.4136  0.1659 -2.49  0.0127  \nrx=5.0 mg estrogen  -0.1044  0.1572 -0.66  0.5066  \n. . .                                              \n\n\nLR 119.86 with 24 degrees of freedom. AIC is \\(119.86-2 \\cdot 24=71.86\\). Rough shrinkage estimate of this is now better at \\((119.86-24)/119.86=0.80\\).\n\nanova(f, html = T)\n\n                Wald Statistics          Response: S \n\n Factor          Chi-Square d.f. P     \n rx                7.92      3   0.0476\n age              13.65      3   0.0034\n  Nonlinear        8.94      2   0.0115\n wt                8.23      2   0.0163\n  Nonlinear        2.57      1   0.1092\n pf_linear         3.50      1   0.0615\n heart_d          24.91      1   &lt;.0001\n map               0.05      2   0.9753\n  Nonlinear        0.05      1   0.8232\n hg               12.49      3   0.0059\n  Nonlinear        8.10      2   0.0174\n sg                1.70      2   0.4269\n  Nonlinear        0.05      1   0.8318\n sz               12.43      2   0.0020\n  Nonlinear        0.07      1   0.7888\n ap                6.46      4   0.1672\n  Nonlinear        6.16      3   0.1042\n bm                0.03      1   0.8523\n TOTAL NONLINEAR  23.58     11   0.0146\n TOTAL           120.27     24   &lt;.0001\n\n\nWe see that the p-value for the treatment, doses of estrogen (rx), is below \\(0.05\\), so it seems like it has some effect."
  },
  {
    "objectID": "projects/cox_model/cox.html#checking-proportional-hazards",
    "href": "projects/cox_model/cox.html#checking-proportional-hazards",
    "title": "Cox model case study",
    "section": "Checking Proportional Hazards",
    "text": "Checking Proportional Hazards\nA Cox model should have proportional hazards, since if we look at two individuals with covariate values \\(\\boldsymbol{X}\\) and \\(\\boldsymbol{X}^*\\) then the ratio of their hazard rates is \\[\\frac{h(t \\vert \\boldsymbol{X})}{h(t \\vert \\boldsymbol{X}^*)}=\\exp\\Big[\\sum_{k=1}^p \\beta_k(X_k-X_{k^*})\\Big],\\] which is a constant. We can test this assumption using scaled Schoenfeld residuals separately for each predictor and test the PH assumption using the “correlation with time” test. Smoothed trends in the residuals are also plotted.\n\nz &lt;- predict(f, type = \"terms\")\nf.short &lt;- cph(S ~ z, x = TRUE, y = TRUE)\nphtest &lt;- cox.zph(f.short, transform = \"identity\", terms = F)\nphtest\n\n             chisq df     p\nrx        3.906254  1 0.048\nage       1.218347  1 0.270\nwt        0.016868  1 0.897\npf_linear 0.190007  1 0.663\nheart_d   0.360714  1 0.548\nmap       0.046079  1 0.830\nhg        0.018155  1 0.893\nsg        0.904761  1 0.342\nsz        0.218858  1 0.640\nap        0.009228  1 0.923\nbm        0.000329  1 0.986\nGLOBAL    7.813453 11 0.730\n\n\nWe see that the p-value of the test for proportional hazards is below \\(0.05\\) for dose of estrogen, indicating that it may not have constant relative hazard. We plot it and don’t find anything too worry-some, and the global test of proportional hazard by adjusting for the 11 tests gives a p-value of \\(0.78\\). So we accept our model and continue.\n\nplot(phtest, var = \"rx\")"
  },
  {
    "objectID": "projects/cox_model/cox.html#describing-effects",
    "href": "projects/cox_model/cox.html#describing-effects",
    "title": "Cox model case study",
    "section": "Describing Effects",
    "text": "Describing Effects\nWe plot how each predictor is related to the log hazard of death with \\(95\\%\\)-confidence bands.\n\nggplot(Predict(f),\n  sepdiscrete = \"vertical\", nlevels = 4,\n  vnames = \"names\"\n)"
  },
  {
    "objectID": "projects/cox_model/cox.html#validating-the-model",
    "href": "projects/cox_model/cox.html#validating-the-model",
    "title": "Cox model case study",
    "section": "Validating the model",
    "text": "Validating the model\nWe will use bootstrapping for validation. We first validate this model for Somers’ \\(D_{xy}\\) rank correlation between predicted log hazard and observed survival time, and for slope shrinkage. The bootstrap is used (with 1000 resamples) to penalize for possible overfitting.\n\nv &lt;- validate(f, B = 1000)\noptions(prType = \"html\")\nv\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndex\nOriginal\nSample\nTraining\nSample\nTest\nSample\nOptimism\nCorrected\nIndex\nSuccessful\nResamples\n\n\n\n\nDxy\n-0.3228\n-0.3517\n-0.2979\n-0.0538\n-0.269\n1000\n\n\nR2\n0.2125\n0.2521\n0.1781\n0.074\n0.1385\n1000\n\n\nSlope\n1\n1\n0.7849\n0.2151\n0.7849\n1000\n\n\nD\n0.0296\n0.0361\n0.0242\n0.0119\n0.0177\n1000\n\n\nU\n-5e-04\n-5e-04\n0.0025\n-0.003\n0.0025\n1000\n\n\nQ\n0.0301\n0.0366\n0.0217\n0.0149\n0.0152\n1000\n\n\ng\n0.7245\n0.812\n0.6359\n0.1762\n0.5483\n1000\n\n\n\n\n\nHere “training” refers to accuracy when evaluated on the bootstrap sample used to fit the model, and “test” refers to the accuracy when this model is applied without modification to the original sample. The apparent \\(D_{xy}\\) is 0.32, but a better estimate of how well the model will discriminate prognoses in the future is \\(D_{xy} = 0.27\\). The bootstrap estimate of slope shrinkage is \\(0.79\\), close to the simple heuristic estimate.\n\nValidate the model for predicting the probability of surviving five years\nWe will use the non-shrinked estimates to show that this model will have some overfitting consistent with regression to the mean.\n\ncal &lt;- calibrate(f, B = 1000, u = 5 * 12)\n\nUsing Cox survival estimates at 60 Months\nConvergence problems.... stopping addition\n\nplot(cal, subtitles = FALSE)\n\n\n\n\n\n\n\n\nThe line nearer the ideal line corresponds to apparent predictive accuracy. The blue curve corresponds to bootstrap-corrected estimates. We clearly see some regression to the mean."
  },
  {
    "objectID": "projects/cox_model/cox.html#final-model-for-prediction",
    "href": "projects/cox_model/cox.html#final-model-for-prediction",
    "title": "Cox model case study",
    "section": "Final model for prediction",
    "text": "Final model for prediction\nFor a better model for prediction one should multiply the coefficients in the model by the shrinkage estimate.\n\nv\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndex\nOriginal\nSample\nTraining\nSample\nTest\nSample\nOptimism\nCorrected\nIndex\nSuccessful\nResamples\n\n\n\n\nDxy\n-0.3228\n-0.3517\n-0.2979\n-0.0538\n-0.269\n1000\n\n\nR2\n0.2125\n0.2521\n0.1781\n0.074\n0.1385\n1000\n\n\nSlope\n1\n1\n0.7849\n0.2151\n0.7849\n1000\n\n\nD\n0.0296\n0.0361\n0.0242\n0.0119\n0.0177\n1000\n\n\nU\n-5e-04\n-5e-04\n0.0025\n-0.003\n0.0025\n1000\n\n\nQ\n0.0301\n0.0366\n0.0217\n0.0149\n0.0152\n1000\n\n\ng\n0.7245\n0.812\n0.6359\n0.1762\n0.5483\n1000\n\n\n\n\nshrinkage_est &lt;- v[3, 5] # Extract bootstrap estimate of shrinkage\nf_prediction &lt;- f\nf_prediction$coefficients &lt;- f$coefficients * shrinkage_est\n\nprint(f_prediction, html = T, coef = 3)\n\n\nCox Proportional Hazards Model\n\ncph(formula = S ~ rx + rcs(age, 4) + rcs(wt, 3) + pf_linear + \n    heart_d + rcs(map, 3) + rcs(hg, 4) + rcs(sg, 3) + rcs(sz, \n    3) + rcs(log(ap), 5) + bm, x = TRUE, y = TRUE, surv = TRUE, \n    time.inc = 5 * 12)\n\n\n\n\n\n\n\n\n\n\n\n\nModel Tests\nDiscrimination\nIndexes\n\n\n\n\nObs 502\nLR χ2 119.86\nR2 0.212\n\n\nEvents 354\nd.f. 24\nR224,502 0.174\n\n\nCenter -2.3792\nPr(&gt;χ2) 0.0000\nR224,354 0.237\n\n\n\nScore χ2 126.89\nDxy -0.323\n\n\n\nPr(&gt;χ2) 0.0000\n\n\n\n\n\n\n\n\n\n\n\n\nβ\nS.E.\nWald Z\nPr(&gt;|Z|)\n\n\n\n\nrx=0.2 mg estrogen\n  0.0004\n  0.1492\n0.00\n0.9980\n\n\nrx=1.0 mg estrogen\n  -0.3246\n  0.1659\n-1.96\n0.0504\n\n\nrx=5.0 mg estrogen\n  -0.0819\n  0.1572\n-0.52\n0.6022\n\n\n…\n\n\n\n\n\n\n\n\n\n\nApproximating the full model\nIf the client doesn’t want to collect all these variables for prediction we can do model approximation. The goal is to explain f_predictionwith a trade off between parameters and \\(R^2\\). This can be done by backwards selection.\n\nZ &lt;- predict(f_prediction) # compute linear predictor from full model\n\nWarning in formula.character(object, env = baseenv()): Using formula(x) is deprecated when x is a character vector of length &gt; 1.\n  Consider formula(paste(x, collapse = \" \")) instead.\n\n# Force sigma to be 1 since perfect fit\na &lt;- ols(Z ~ rx + rcs(age, 4) + rcs(wt, 3) + pf_linear + heart_d + rcs(map, 3)\n  + rcs(hg, 4) + rcs(sg, 3) + rcs(sz, 3) + rcs(log(ap), 5) + bm, sigma = 1)\n\nbackwards &lt;- fastbw(a, aics = 10000)\nprint(backwards, html = T, digits = 3)\n\n\n Deleted   Chi-Sq d.f. P      Residual d.f. P      AIC    R2   \n map        0.07  2    0.9641   0.07    2   0.9641  -3.93 1.000\n bm         0.04  1    0.8321   0.12    3   0.9896  -5.88 0.999\n sg         2.50  2    0.2861   2.62    5   0.7582  -7.38 0.987\n pf_linear  4.88  1    0.0271   7.51    6   0.2767  -4.49 0.964\n rx        15.66  3    0.0013  23.16    9   0.0058   5.16 0.888\n wt        12.41  2    0.0020  35.57   11   0.0002  13.57 0.828\n age       16.50  3    0.0009  52.08   14   0.0000  24.08 0.748\n ap        19.61  4    0.0006  71.69   18   0.0000  35.69 0.653\n hg        36.53  3    0.0000 108.22   21   0.0000  66.22 0.475\n sz        42.83  2    0.0000 151.04   23   0.0000 105.04 0.268\n heart_d   55.27  1    0.0000 206.31   24   0.0000 158.31 0.000\n\nApproximate Estimates after Deleting Factors\n\n         Coef   S.E.  Wald Z P\n[1,] 7.58e-11 0.0446 1.7e-09 1\n\nFactors in Final Model\n\nNone\n\n\nNow the client can choose the trade-off between predictive ability and number of predictors. We visualize this in the following plot\n\nresult &lt;- as.data.frame(backwards$result)\ntotal_predictors &lt;- nrow(result)\nR2 &lt;- result$R2\npredictors &lt;- c((total_predictors - 1):0)\n\nggplot(data.frame(predictors, R2), aes(x = predictors, y = R2)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"red\") +\n  labs(x = \"Predictors\", y = TeX(\"$R^2$\")) +\n  ggtitle(\"R-squared vs. Predictors\") +\n  scale_y_continuous(breaks = pretty_breaks()) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nA reasonable approach trade off would be to remove map, bm, sg and pf_linear from our model to get an approximate model which still has high \\(R^2\\) of \\(0.96\\) for explaining the full model.\n\nf_approx &lt;- ols(Z ~ rx + rcs(age, 4) + rcs(wt, 3) + heart_d\n  + rcs(hg, 4) + rcs(sz, 3) + rcs(log(ap), 5), x = T)\n\nprint(f_approx, html = T, coefs = 3)\n\n\nLinear Regression Model\n\nols(formula = Z ~ rx + rcs(age, 4) + rcs(wt, 3) + heart_d + rcs(hg, \n    4) + rcs(sz, 3) + rcs(log(ap), 5), x = T)\n\n\n\n\n\n\n\n\n\n\n\n\nModel Likelihood\nRatio Test\nDiscrimination\nIndexes\n\n\n\n\nObs 502\nLR χ2 1663.53\nR2 0.964\n\n\nσ 0.1247\nd.f. 18\nR2adj 0.962\n\n\nd.f. 483\nPr(&gt;χ2) 0.0000\ng 0.713\n\n\n\n\n\n\nResiduals\n\n     Min       1Q   Median       3Q      Max \n-0.30962 -0.07092 -0.02333  0.04420  0.63137 \n\n\n\n\n\n\n\n\nβ\nS.E.\nt\nPr(&gt;|t|)\n\n\n\n\nIntercept\n  3.7212\n 0.1976\n18.83\n&lt;0.0001\n\n\nrx=0.2 mg estrogen\n  0.0070\n 0.0158\n0.44\n0.6600\n\n\nrx=1.0 mg estrogen\n  -0.4338\n 0.0159\n-27.32\n&lt;0.0001\n\n\n…"
  },
  {
    "objectID": "projects/bachelor_thesis/bachelor_thesis.html",
    "href": "projects/bachelor_thesis/bachelor_thesis.html",
    "title": "Bachelor Thesis: Asymptotic Normality for Tessellation-based Betti Numbers",
    "section": "",
    "text": "In this project I worked on Topological Data Analysis. In particular, I proved some Central Limit Theorems for Tessellation based Betti numbers.\n\nClick here to download the thesis"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Read more about Quarto blogs here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/post-with-code/index.html",
    "href": "blog/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bjarke Hautop Kristensen",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Github\n  \n  \n      email\n  \n\n  \n  \nWelcome to my website!\n\n\nAarhus University | Aarhus, Denmark.\nStudying a master in Statistics | 2023-2025\n\n\n\nClick here to download my CV\n\n\n\n\nChess\nPowerlifting",
    "crumbs": [
      "About me"
    ]
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Bjarke Hautop Kristensen",
    "section": "",
    "text": "Aarhus University | Aarhus, Denmark.\nStudying a master in Statistics | 2023-2025",
    "crumbs": [
      "About me"
    ]
  },
  {
    "objectID": "about.html#cv",
    "href": "about.html#cv",
    "title": "Bjarke Hautop Kristensen",
    "section": "",
    "text": "Click here to download my CV",
    "crumbs": [
      "About me"
    ]
  },
  {
    "objectID": "about.html#hobbies",
    "href": "about.html#hobbies",
    "title": "Bjarke Hautop Kristensen",
    "section": "",
    "text": "Chess\nPowerlifting",
    "crumbs": [
      "About me"
    ]
  },
  {
    "objectID": "blog/welcome/index.html",
    "href": "blog/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My website",
    "section": "",
    "text": "Welcome to my website dedicated to statistics. Here, you’ll find information, resources, and insights on some of my interests.\n\n\nContact me at bjarke.hautop@gmail.com."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "My website",
    "section": "",
    "text": "Welcome to my website dedicated to statistics. Here, you’ll find information, resources, and insights on some of my interests.\n\n\nContact me at bjarke.hautop@gmail.com."
  },
  {
    "objectID": "projects/bayesian_disease/bayesian_disease.html",
    "href": "projects/bayesian_disease/bayesian_disease.html",
    "title": "Bayesian approach to disease outbreaks",
    "section": "",
    "text": "In this project we will consider a Bayesian approach to modelling disease outbreaks inspired by this Stan case study. We will do this using a Susceptible-Infected-Recovered (SIR) model. The main objective is to estimate epidemiological parameters of interest."
  },
  {
    "objectID": "projects/bayesian_disease/bayesian_disease.html#sampling-distribution",
    "href": "projects/bayesian_disease/bayesian_disease.html#sampling-distribution",
    "title": "Bayesian approach to disease outbreaks",
    "section": "Sampling distribution",
    "text": "Sampling distribution\nGiven our parameters and initial conditions we can find the number of infected students, \\(I_{\\text{ODE}}(t)\\). We want to link this solution to the observed data, i.e. the number of students in bed, \\(I_{\\text{obs}}(t)\\). That is, our observed is a noisy estimate of the true number of infected students. To allow for possible overdispersion we choose to sample from a negative binomial distribution. \\[I_{\\text{obs}}(t) \\sim \\text{NegBin}(I_{\\text{ODE}}(t), \\phi)\\] So, we have \\(p(\\mathcal{Y}\\vert \\theta)\\) with \\(\\theta=(\\beta,\\gamma,\\phi)\\)."
  },
  {
    "objectID": "projects/bayesian_disease/bayesian_disease.html#prior-distribution",
    "href": "projects/bayesian_disease/bayesian_disease.html#prior-distribution",
    "title": "Bayesian approach to disease outbreaks",
    "section": "Prior distribution",
    "text": "Prior distribution\nWe select a prior for each of the three parameters \\(\\beta,\\gamma\\), and \\(\\phi\\). For the rate of which susceptible people become infected, \\(\\beta\\), we use a normal distribution truncated at \\(0\\). Using domain knowledge a reasonable choice is to have the mean be \\(2\\) and \\(P(\\beta&gt;3)=0.2\\). To do this we will need code to numerically solve for these parameters.\n\n\nClick here to see code for solving for parameters in truncated normal\n\nI made the function solve_truncated_normal in my package solvetruncated, which can be downloaded by running the following code:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"BjarkeHautop/solvetruncated\")\n\nWe can then use the function to solve for the parameters. For example, to solve for the parameters of \\[X \\sim \\text{Normal}^+(\\mu, \\sigma)\\] with desired mean \\(E[X]=0.5\\) and \\(P(X\\leq 0.75)=0.8\\).\n\nlibrary(solvetruncated)\nsolve_truncated_normal(desired_mean = 0.5, x_value = 0.75, desired_prob = 0.8, a = 0, b = Inf)\n\n$mu\n[1] 0.4208603\n\n$sigma\n[1] 0.3543778\n\n\n\nNow we can solve for the parameters for \\(\\beta\\) numerically.\n\nsolve_truncated_normal(desired_mean = 2, x_value = 3, desired_prob = 1 - 0.2)\n\n$mu\n[1] 1.683441\n\n$sigma\n[1] 1.417511\n\n\nThus, \\[\\beta \\sim \\mathrm{Normal}^+(1.68,\\; 1.42^2).\\]\nFor \\(\\gamma\\) we will also use truncated normal distribution, where we know that typically an influenza lasts a few days. In particular, we want the mean of \\(\\gamma\\) to be \\(0.5\\), so the average length of the infectious disease is \\(1/\\gamma=1/0.5=2\\). We also want the recovery time to be more than \\(1\\) day with probability \\(0.9\\) (that is \\(P(\\gamma\\leq 1)=0.9\\)). We again solve for the parameters numerically.\n\nsolve_truncated_normal(desired_mean = 0.5, x_value = 1, desired_prob = 0.9)\n\n$mu\n[1] 0.1771892\n\n$sigma\n[1] 0.5375236\n\n\nThus, \\[\\gamma \\sim \\mathrm{Normal}^+(0.18, \\; 0.54^2),\\]\nFor the overdispersion parameter \\(\\phi\\) we will use a generic prior on \\(1/\\sqrt{\\phi}\\) as recommended by Stan here, that is \\[1/\\sqrt{\\phi} \\sim \\mathrm{Normal}^+(0,\\; 1^2).\\]"
  },
  {
    "objectID": "projects/bayesian_disease/bayesian_disease.html#quantities",
    "href": "projects/bayesian_disease/bayesian_disease.html#quantities",
    "title": "Bayesian approach to disease outbreaks",
    "section": "Quantities",
    "text": "Quantities\nIn infectious disease models, a key parameter of interest is often the basic reproduction number, \\(R_0\\). \\(R_0\\) represents the average number of secondary infections generated by a single infected individual in a completely susceptible population over the entire infectious period. \\(R_0&gt;1\\) indicates a sustainable infection, which can lead to a major outbreak, while \\(R_0&lt;1\\) suggests that the infection will die out. Bayesian inference allows us to construct a posterior distribution for \\(p(R_0\\vert \\mathcal{Y})\\).\nThe other quantities we will track is recovery time and predicted number of cases."
  },
  {
    "objectID": "projects/bayesian_disease/bayesian_disease.html#coding-the-model-in-stan",
    "href": "projects/bayesian_disease/bayesian_disease.html#coding-the-model-in-stan",
    "title": "Bayesian approach to disease outbreaks",
    "section": "Coding the model in Stan",
    "text": "Coding the model in Stan\n\n\nClick here to see details about how to code the model in Stan\n\nThe full code for our Stan model is\n\n// Code for ODE\nfunctions {\n  vector sir(real t, vector y, array[] real theta, \n             array[] real x_r, array[] int x_i) {\n\n      real S = y[1];\n      real I = y[2];\n      real R = y[3];\n      real N = x_i[1];\n      \n      real beta = theta[1];\n      real gamma = theta[2];\n      \n      real dS_dt = -beta * I * S / N;\n      real dI_dt =  beta * I * S / N - gamma * I;\n      real dR_dt =  gamma * I;\n      \n      // ' transposes our row vector into a column vector\n      return [dS_dt, dI_dt, dR_dt]';\n  }\n}\n\ndata {\n  int&lt;lower=1&gt; n_days;\n  vector[3] y0;\n  array[n_days] real t;\n  int N;\n  array [n_days] int cases;\n}\n\n// Track status of individuals in SIR model in x\ntransformed data {\n  real t0 = 0; \n  array[0] real x_r;\n  array[1] int x_i = { N };\n}\n\n// Truncated prior using &lt;lower=...&gt;\nparameters {\n  real&lt;lower=0&gt; beta;\n  real&lt;lower=0&gt; gamma;\n  real&lt;lower=0&gt; phi_inv_sqrt;\n}\n\ntransformed parameters{\n  array[n_days] vector[3] y;\n  real phi = 1. / (square(phi_inv_sqrt));\n  {\n    array[2] real theta;\n    theta[1] = beta;\n    theta[2] = gamma;\n\n    y = ode_rk45(sir, y0, t0, t, theta, x_r, x_i);\n  }\n}\n\nmodel {\n  //priors \n  beta ~ normal(1.7, 1.4); \n  gamma ~ normal(0.2, 0.53);\n  phi_inv_sqrt ~ normal(0, 1);\n  \n  // sampling distribution\n  cases ~ neg_binomial_2(y[,2], phi);\n}\n\n// Quantities of interest\ngenerated quantities {\n  real R0 = beta / gamma;\n  real recovery_time = 1 / gamma;\n  array[n_days] real pred_cases;\n  pred_cases = neg_binomial_2_rng(y[,2], phi);\n}\n\n\nWe now define the model.\n\nmodel &lt;- stan_model(file = file_path)"
  },
  {
    "objectID": "projects/bayesian_disease/bayesian_disease.html#running-stan-model",
    "href": "projects/bayesian_disease/bayesian_disease.html#running-stan-model",
    "title": "Bayesian approach to disease outbreaks",
    "section": "Running Stan model",
    "text": "Running Stan model\nWe run our model with default options.\n\ncases &lt;- influenza_england_1978_school$in_bed\n\n# total count\nN &lt;- 763\n# times\nn_days &lt;- length(cases)\nt &lt;- seq(0, n_days, by = 1)\nt &lt;- t[-1]\n\n# initial conditions\ni0 &lt;- 1\ns0 &lt;- N - i0\nr0 &lt;- 0\ny0 &lt;- c(S = s0, I = i0, R = r0)\n\n# data for Stan\ndata_sir &lt;- list(\n  n_days = n_days, y0 = y0, t = t, N = N,\n  cases = cases\n)\n\nfit_sir_negbin &lt;- stan(\n  file = file_path,\n  data = data_sir,\n  seed = 1405,\n)"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Bayesian approach to disease outbreaks\n\n\n\n\n\n\nBayesian\n\n\nR\n\n\nStan\n\n\n\n\n\n\n\n\n\nJuly, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nNotes to Regression Modelling Strategies by Frank Harrell\n\n\n\n\n\n\nNotes\n\n\nR\n\n\n\n\n\n\n\n\n\nJuly, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCox model case study\n\n\n\n\n\n\nSurvival analysis\n\n\nR\n\n\n\n\n\n\n\n\n\nJuly, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nBachelor Thesis: Asymptotic Normality for Tessellation-based Betti Numbers\n\n\n\n\n\n\nTDA\n\n\nBachelor Thesis\n\n\nPython\n\n\n\n\n\n\n\n\n\nJune, 2023\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Projects"
    ]
  },
  {
    "objectID": "projects/pkg_1/index.html",
    "href": "projects/pkg_1/index.html",
    "title": "pkg_1",
    "section": "",
    "text": "This package does this."
  }
]